# 编程技巧
<a name="oawdB"></a>
# 性能优化
<a name="rCAOt"></a>
## 数据结构
<a name="nFvpm"></a>
### 反射
反射的可读性比较差，推荐使用泛型。常见优化方式：

1. 缓存反射结果，减少不必要的反射次数。例如 [json-iterator](https://github.com/json-iterator/go)。
2. 直接使用`unsafe.Pointer`根据各个字段偏移赋值。
3. 消除一般的 struct 反射内存消耗 [go-reflect](https://github.com/goccy/go-reflect)。
4. 避免一些类型转换，如`interface->[]byte`。
5. 基本数据类型与字符串之间的转换，优先使用 [strconv](https://pkg.go.dev/strconv) 而不是 [fmt](https://pkg.go.dev/fmt)，性能上会有两倍多的差距，因为`fmt`利用反射来达到范型的效果，运行时的动态类型判断带来了性能损耗。
6. `[binary.Read()](https://pkg.go.dev/encoding/binary#Read)` 和 `[binary.Write()](https://pkg.go.dev/encoding/binary#Write)` 使用反射并且很慢。如果有需要手动实现这两个函数的相关功能，而不是直接使用它们。
<a name="borhB"></a>
### 字符串与字节切片的转换
不要反复从固定字符串创建字节 slice，重复的切片初始化会带来性能损耗。应该执行一次转换并保存结果。
<a name="J5ztV"></a>
### 指定容器容量
尽可能指定容器容量，以便为容器预先分配内存。这将在后续添加元素时减少通过复制来调整容器大小。

1. 指定 **map** 容量：`make(map[T1]T2, hint)`
2. 指定 **slice** 容量：`make([]T, length, capacity)`
> 编译器将为提供给 `make()` 的 slice 的容量分配足够的内存，这意味着后续的 `append()` 操作将导致零分配（直到 slice 的长度与容量匹配，在此之后，任何 append 都可能调整大小以容纳其他元素）
> 与 slice 不同，map capacity 提示并不保证完全的抢占式分配，而是用于估计所需的 hashmap bucket 的数量。因此，在将元素添加到 map 时，甚至在指定 map 容量时，仍可能发生分配。

<a name="Tf8ap"></a>
### 字符串拼接方式

1. 行内拼接字符串推荐使用运算符`+`，也可使用`[fmt.Sprintf()](https://pkg.go.dev/fmt#Sprintf)`：从性能出发，兼顾易用可读，如果待拼接的变量不涉及类型转换且数量较少（<=5），行内拼接字符串推荐使用运算符 +，反之使用 `fmt.Sprintf()`。
2. 非行内拼接字符串推荐使用 `[strings.Builder](https://pkg.go.dev/strings#Builder)`：还有其他的方式，比如`[strings.Join()](https://pkg.go.dev/strings#Join)`、`[bytes.Buffer](https://pkg.go.dev/bytes#Buffer)`和`byte[]`，这几种不适合行内使用。当待拼接字符串数量较多时可考虑使用。

从性能测试的结果看：`strings.Join()`、`strings.Builder`、`bytes.Buffer`和`byte[]`的性能相近。

- 如果结果字符串的长度是可预知的，使用 `byte[]` 且预先分配容量的拼接方式性能最佳。
- 如果对性能要求非常严格，或待拼接的字符串数量足够多时，建议使用 `byte[]`预先分配容量这种方式
- 综合易用性和性能，一般推荐使用`strings.Builder`来拼接字符串。
<a name="NFn6W"></a>
### 遍历 `[]struct{}` 使用下标而不是`range`
Go 中遍历切片或数组有两种方式，一种是通过下标，一种是 range。二者在功能上没有区别，但是在性能上有区别。

1. 遍历基本数据类型：下标与 range 遍历性能几乎没有区别。
2. 遍历`[]struct{}`：`range` 遍历`[]struct`中元素时，性能非常差，只遍历`[]struct`下标时，性能比遍历 `[]struct`值好很多，因为 `range` 时获取的是值拷贝的副本，带来了性能损耗，并且对副本的修改，是不会影响到原切片。
3. 遍历`[]*struct{}`：性能几乎是一样的，而且使用指针可以直接修改指针对应的结构体的值。
<a name="LJLWm"></a>
## 内存管理
<a name="naY4z"></a>
### 使用空结构体节省内存
在 Go 中使用`[unsafe.Sizeof()](https://pkg.go.dev/unsafe#Sizeof)`计算出一个数据类型实例需要占用的字节数。空结构体`struct{}{}`是不占用内存空间，因此被广泛作为各种场景下的占位符使用。一是**节省资源**，二是空结构体本身就具备**很强的语义**，即这里不需要任何值，仅作为占位符，达到的代码即注释的效果。

1. 实现集合（Set）:`type Set map[string]struct{}`，如果值设置为`bool`，那也需要多占用1个字节，100万数据的时候，就多1MB的内存。例如 [golang-set](https://github.com/deckarep/golang-set)
2. 不发送数据的通道（channel）： 当 channel 不需要发送任何的数据，只用来通知子协程 Goroutine执行任务，或只用来控制协程的并发。使用空结构体作为占位符就非常合适了。
3. 仅包含方法的结构体：`type Door struct{}`，在部分场景下，结构体只包含方法，不包含任何的字段。例如上面例子中的 Door，在这种情况下，Door 事实上可以用任何的数据结构替代。无论是 `int` 还是 `bool` 都会浪费额外的内存，声明为空结构体最合适。
<a name="Msbxv"></a>
### `struct`内存对齐
CPU 访问内存时，以字长（word size）为单位访问。比如 32 位的字长为 4 字节，64 位的字长为 8 字节。这么设计是减少 CPU 访问内存的次数，加大 CPU 访问内存的吞吐量。如果不进行内存对齐，就可能增加 CPU 访问内存的次数。<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/362867/1670295671817-62acf644-b654-42b2-9a44-2177f103326f.png#averageHue=%23f7eee9&clientId=ub2c23a40-c310-4&from=paste&height=300&id=u23956dff&originHeight=600&originWidth=990&originalType=binary&ratio=1&rotation=0&showTitle=false&size=148468&status=done&style=none&taskId=u2d541133-0d0a-479e-8ca5-58c5ed7f2c3&title=&width=495)<br />在非对齐的情况下，CPU 读取变量 b 需要进行 2 次内存访问。<br />内存对齐对实现变量的原子性操作也是有好处的，每次内存访问是原子的，如果变量的大小不超过字长，那么内存对齐后，对该变量的访问就是原子的，这个特性在并发场景下至关重要。<br />编译器一般为了减少 CPU 访存指令周期，提高内存的访问效率，会对变量进行内存对齐。Go 作为一门追求高性能的后台编程语言，当然也不例外，内存对齐规则如下：

- 对于任意类型的变量`x` ，`unsafe.Alignof(x)`至少为 1。
- 对于结构体类型的变量`x`，计算`x`每一个字段`f`的`unsafe.Alignof(x.f)`，`unsafe.Alignof(x)`等于其中的最大值。
- 对于数组类型的变量`x`，`unsafe.Alignof(x)`等于构成数组的元素类型的对齐系数。

其中函数`unsafe.Alignof()`用于获取变量的对齐系数。对齐系数决定了字段的偏移和变量的大小，两者必须是对齐系数的整数倍。

1. 合理的`struct` 布局：利用内存对齐可以减少内存占用，同时提高程序性能。**在对内存特别敏感的结构体的设计上，将字段宽度从小到大由上到下排列，来减少内存的占用。**
2. 空结构体和空数组对内存对齐的影响：没有任何字段的空`struct{}`和没有任何元素的`array`占据的内存空间大小为 0。
   1. 空`struct{}`或空`array`作为其他 struct 的字段时，一般不需要内存对齐。
   2. 当`struct{}`或空`array`作为结构体最后一个字段时，需要内存对齐（该字段会额外占用内存）。因为如果有指针指向该**字段**，返回的地址将在结构体之外，如果此指针一直存活不释放对应的内存，就会有**内存泄露**的问题（该内存不因结构体释放而释放）。
<a name="uzR1V"></a>
### 减少逃逸
变量逃逸一般发生在如下几种情况：

- 变量较大（大于32KB）
- 变量大小不确定
- 变量类型不确定
- 返回指针
- 返回引用
- 闭包

有意识的控制变量不发生逃逸，将其控制在栈上，减少堆变量的分配，降低 GC 成本，提高程序性能。

1. 小的拷贝好过引用：尽量使用栈变量而不是堆变量
2. 返回值（值传递会拷贝整个对象） VS 返回指针（指针传递只会拷贝地址）：返回指针可以减少值的拷贝，但是会导致内存分配逃逸到堆中，增加 GC 的负担。在对象频繁创建和删除的场景下，传递指针导致的 GC 开销可能会严重影响性能。一般情况下：
   1. 对于需要修改原对象值或占用内存比较大的结构体，选择返回指针。
   2. 对于只读的占用内存较小的结构体，直接返回值能够获得更好的性能。
3. 返回值使用确定的类型：如果变量类型不确定将会逃逸到堆上，所以，函数返回值如果能确定的类型，就不要使用`interface{}`。
<a name="ALQMw"></a>
### `[sync.Pool](https://pkg.go.dev/sync#Pool)`
作为临时对象池是对可读性影响最小且优化效果显著的手段。`sync.Pool`是可伸缩的，并发安全的，其容量仅受限于内存的大小，存放在池中的对象如果不活跃了会被自动清理。

1. 利用这些特性可以减少锁的竞争，在优化前要用逃逸分析检查对象是否逃逸到堆上，防止负优化。
2. 对于需要重复分配和回收内存的地方，用来保存和复用临时对象，减少内存分配，降低 GC 压力，提升系统性能

Go 标准库也大量使用了`sync.Pool`，例如`fmt`和`encoding/json`，如下以`[fmt.Fprintf()](https://pkg.go.dev/fmt#Fprintf)`为例，`fmt.Printf()`的调用是非常频繁的，利用`sync.Pool`复用`pp`对象能够极大地提升性能，减少内存占用，同时降低 GC 压力。
```go
// pp is used to store a printer's state and is reused with sync.Pool to avoid allocations.
type pp struct {
	buf buffer

	// arg holds the current item, as an interface{}.
	arg any

	// value is used instead of arg for reflect values.
	value reflect.Value

	// fmt is used to format basic items such as integers or strings.
	fmt fmt

	// reordered records whether the format string used argument reordering.
	reordered bool
	// goodArgNum records whether the most recent reordering directive was valid.
	goodArgNum bool
	// panicking is set by catchPanic to avoid infinite panic, recover, panic, ... recursion.
	panicking bool
	// erroring is set when printing an error string to guard against calling handleMethods.
	erroring bool
	// wrapErrs is set when the format string may contain a %w verb.
	wrapErrs bool
	// wrappedErr records the target of the %w verb.
	wrappedErr error
}

var ppFree = sync.Pool{
	New: func() any { return new(pp) },
}

// newPrinter allocates a new pp struct or grabs a cached one.
func newPrinter() *pp {
	p := ppFree.Get().(*pp)
	p.panicking = false
	p.erroring = false
	p.wrapErrs = false
	p.fmt.init(&p.buf)
	return p
}

// These routines end in 'f' and take a format string.

// Fprintf formats according to a format specifier and writes to w.
// It returns the number of bytes written and any write error encountered.
func Fprintf(w io.Writer, format string, a ...any) (n int, err error) {
	p := newPrinter()
	p.doPrintf(format, a)
	n, err = w.Write(p.buf)
	p.free()
	return
}
```
<a name="jSo7M"></a>
### 复用对象
string2bytes / bytes2string：

1. 复用对象，减少内存分配
2. string2bytes 后不能对其修改
```go
func gostringnocopy(str *byte) string {
    ss := stringStruct{str: unsafe.Pointer(str), len: findnull(str)}
    s := *(*string)(unsafe.Pointer(&ss))
    return s
}
```
<a name="TUkGm"></a>
## 并发编程
<a name="IJN85"></a>
### `map`/`slice`

1. map 和 slice 都不是并发安全
   1. map：`sync.Mutex` / `sync.Map`（读多写少）
   2. slice：`sync.Mutex`
2. map 和 slice 参数传递问题
   1. map：因为操作对象一直是引用，即使扩容后引用的地址不会改变，所以不会出现时而可以修改，时而不能修改的情况
   2. slice：
      1. 只对基础值类型在传参中使用**深拷贝**，对于 slice 和 map 使用**浅拷贝**，作为传参其指向的内存地址依然是原数据。
      2. slice扩容机制的影响：向 slice 中添加元素超出容量时会触发扩容机制，创建一份新的原数据，此时，与**浅拷贝**获取的变量没有任何关联的。
<a name="avOTO"></a>
### 锁
加锁是为了避免在并发环境下，同时访问共享资源产生的安全问题，适当地降低锁的粒度，甚至采用无锁化的设计（无锁数据结构或串行无锁），更能提升并发能力。

1. 无锁数据结构**：**利用硬件支持的原子操作实现无锁的数据结构，原子操作在 lock-free 的情况下保证并发安全，并且它的性能也能做到随 CPU 个数的增多而**线性**扩展。如 Go 中的 [atomic](https://pkg.go.dev/sync/atomic) 包。
2. 串行无锁（减小锁粒度）：这是一种思想，就是避免对共享资源的并发访问，改为每个并发操作访问自己独占的资源，达到串行访问资源的效果，来避免使用锁。
   1. 不同的场景有不同的实现方式，比如网络 I/O 场景下将单 Reactor 多线程模型改为主从 Reactor 多线程模型，避免对同一个消息队列锁读取。
   2. [math.rand](https://pkg.go.dev/math/rand) 就有这么一处隐患，直接使用 rand 库生成随机数时，实际上由全局的`[globalRand](https://github.com/golang/go/blob/master/src/math/rand/rand.go#L304)`对象负责生成。globalRand 加锁后生成随机数，会导致在高频使用随机数的场景下效率低下。
   3. 如果加锁无法避免，则可以采用分片的形式，减少对资源加锁的次数，这样也可以提高整体的性能。比如 Golang 优秀的本地缓存组件  [bigcache](https://github.com/allegro/bigcache) 、[go-cache](https://github.com/patrickmn/go-cache)、[freecache](https://github.com/coocood/freecache) 都实现了分片功能，每个分片一把锁，采用分片存储的方式减少加锁的次数从而提高整体性能。
3. 如果并发无法做到无锁化，优先使用共享锁（sync.RWMutex）而非互斥锁（sync.Mutex）：共享锁的读锁不互斥，写锁互斥，读写锁互斥。
<a name="aJI0u"></a>
### 限制协程数量
Goroutine 的开销主要在三个方面：

- 创建（占用内存）：创建一个 `type g struct`，2KB 左右的大小。
- 调度（增加调度器负担）：Goroutine 调度也有 CPU 开销，也就是每个 M 的 g0 的 CPU 开销，一次 Goroutine 的切换大概在 100ns，相对于线程的微秒级耗时切换，性能表现非常优秀，但是仍有开销。
- 删除（增加 GC 压力）：Goroutine 运行结束，占用的内存资源是需要由 GC 来回收，如果无休止地创建大量 Go 程后，势必会造成对 GC 的压力。

Goroutine 数量过多，可能遇到的问题：

   1. Linux 系统对单个 file/socket 的并发操作数是有上限的
   2. 每个协程至少需要消耗 2KB 的空间，无限制的创建 Goroutine 会导致 OOM

系统地资源是有限，Goroutine 是有代价的，为了保护程序，提高性能，我们应主动限制并发的 Goroutine 数量。

1. 利用 channel 的缓冲区大小来限制
2. goroutine pool：绝大部分应用场景，是不需要协程池，Go 对 Goroutine 有一定的复用能力。所以要根据场景选择是否使用协程池，不恰当的场景不仅得不到收益，反而增加系统复杂性。例如，[tunny](https://github.com/Jeffail/tunny) 和 [ants](https://github.com/panjf2000/ants)。
   1. 限制 goroutine 数量，避免无限制的增长。
   2. 减少栈扩容的次数
   3. 频繁创建 Goroutine 的场景下，资源复用，节省内存。（需要一定规模。一般场景下，效果不太明显。）
<a name="dyOKy"></a>
### `[sync.Once](https://pkg.go.dev/sync#Once)`避免重复执行
sync.Once 是 Go 标准库提供的使函数只执行一次的实现，常应用于**单例模式**，例如初始化配置、保持数据库连接等，作用与`init`函数类似，但有区别：

- `init`函数是当所在的 package 首次被加载时执行，若迟迟未被使用，则既浪费了内存，又延长了程序加载时间。
- `sync.Once`可以在代码的任意位置初始化和调用，因此可以延迟到使用时再执行，并发场景下是线程安全的。

在多数情况下，`sync.Once`被用于控制变量的初始化，这个变量的读写满足如下三个条件：

- 当且仅当第一次访问某个变量时，进行初始化（写）；
- 变量初始化过程中，所有读都被阻塞，直到初始化完成；
- 变量仅初始化一次，初始化完成后驻留在内存里。

`sync.Once`用来保证函数只执行一次，要达到这个效果，需要做到两点：

- 计数器，统计函数执行次数；
- 线程安全，保障在多 Go 程的情况下，函数仍然只执行一次，比如锁。
```go
type Once struct {
 // done indicates whether the action has been performed.
 // It is first in the struct because it is used in the hot path.
 // The hot path is inlined at every call site.
 // Placing done first allows more compact instructions on some architectures (amd64/386),
 // and fewer instructions (to calculate offset) on other architectures.
 done uint32
 m    Mutex
}
```
`done`在热路径中，放在第一个字段，能够减少 CPU 指令，提升性能。热路径（hot path）是程序非常频繁执行的一系列指令，`sync.Once`绝大部分场景都会访问`o.done`，在热路径上是比较好理解的。如果 hot path 编译后的机器码指令更少，更直接，必然是能够提升性能的。
> 为什么放在第一个字段就能够减少指令呢？
> 因为结构体第一个字段的地址和结构体的指针是相同的：
> - 如果是第一个字段，直接对结构体的指针解引用即可。
> - 如果是其他的字段，除了结构体指针外，还需要计算与第一个值的偏移（calculate offset）。
> 
在机器码中，偏移量是随指令传递的附加值，CPU 需要做一次偏移值与指针的加法运算，才能获取要访问的值的地址。因此，访问第一个字段的机器代码更紧凑，速度更快。

<a name="LP19V"></a>
### [sync.Cond](https://pkg.go.dev/sync#Cond) 通知协程
`sync.Cond`是基于互斥锁/读写锁实现的条件变量，用来协调想要访问共享资源的那些 Goroutine，当共享资源的状态发生变化的时候，`sync.Cond`可以用来通知等待条件发生而阻塞的 Goroutine。
> sync.Cond 基于互斥锁/读写锁，和互斥锁的区别是什么呢？
> - 互斥锁`sync.Mutex`通常用来保护共享的临界资源，
> - 条件变量`sync.Cond`用来协调想要访问共享资源的 Goroutine。当共享资源的状态发生变化时，`sync.Cond`可以用来通知被阻塞的 Goroutine。

`sync.Cond` 经常用在多个 Goroutine 等待，一个 Goroutine 通知（事件发生）的场景。如果是一个通知，一个等待，使用互斥锁或 channel 就能搞定了。
> 一个简单的场景：
> 有一个 Goroutine 在异步地接收数据，剩下的多个 Goroutine 必须等待这个 Goroutine 接收完数据，才能读取到正确的数据。在这种情况下，如果单纯使用 chan 或互斥锁，那么只能有一个 Goroutine 可以等待，并读取到数据，没办法通知其他的 Goroutine 也读取数据。
> `sync.Cond`就是用来解决这类问题。

`sync.Cond`内部维护了一个等待队列，队列中存放的是所有在等待这个`sync.Cond`的 Goroutine，即保存了一个通知列表。`sync.Cond`可以用来唤醒一个或所有因等待条件变量而阻塞的 Goroutine，以此来实现多个 Goroutine 间的同步。
```go
// Cond implements a condition variable, a rendezvous point
// for goroutines waiting for or announcing the occurrence
// of an event.
//
// Each Cond has an associated Locker L (often a *Mutex or *RWMutex),
// which must be held when changing the condition and
// when calling the Wait method.
//
// A Cond must not be copied after first use.
type Cond struct {
 noCopy noCopy

 // L is held while observing or changing the condition
 L Locker

 notify  notifyList
 checker copyChecker
}
```
每个 Cond 实例都会关联一个锁 L（互斥锁 *Mutex，或读写锁 *RWMutex），当修改条件或者调用 `Wait()` 方法时，必须加锁。
```go
// Wait atomically unlocks c.L and suspends execution
// of the calling goroutine. After later resuming execution,
// Wait locks c.L before returning. Unlike in other systems,
// Wait cannot return unless awoken by Broadcast or Signal.
//
// Because c.L is not locked when Wait first resumes, the caller
// typically cannot assume that the condition is true when
// Wait returns. Instead, the caller should Wait in a loop:
//
//    c.L.Lock()
//    for !condition() {
//        c.Wait()
//    }
//    ... make use of condition ...
//    c.L.Unlock()
//
func (c *Cond) Wait() {
 c.checker.check()
 t := runtime_notifyListAdd(&c.notify)
 c.L.Unlock()
 runtime_notifyListWait(&c.notify, t)
 c.L.Lock()
}
```

- `Wait()`用于阻塞调用者，等待通知。

调用`Wait()`会自动释放锁 `c.L`，并挂起调用者所在的 Goroutine。如果其他 Goroutine 调用了`Signal()`或`Broadcast()`唤醒了该协程，那么`Wait()` 方法在结束阻塞时，会重新给`c.L`加锁，并且继续执行`Wait()`后面的代码。<br />对条件的检查，使用了 `for !condition()`而非 `if`，是因为当前 Goroutine 被唤醒时，条件不一定符合要求，需要再次`Wait()`等待下次被唤醒。为了保险起，使用 for 能够确保条件符合要求后，再执行后续的代码。
```go
// Signal wakes one goroutine waiting on c, if there is any.
//
// It is allowed but not required for the caller to hold c.L
// during the call.
func (c *Cond) Signal() {
 c.checker.check()
 runtime_notifyListNotifyOne(&c.notify)
}

// Broadcast wakes all goroutines waiting on c.
//
// It is allowed but not required for the caller to hold c.L
// during the call.
func (c *Cond) Broadcast() {
 c.checker.check()
 runtime_notifyListNotifyAll(&c.notify)
}
```

- `Signal()`只唤醒任意 1 个等待条件变量 c 的 Goroutine，无需锁保护。
- `Broadcast()`唤醒所有等待条件变量 c 的 Goroutine，无需锁保护。

**注意事项**

- `sync.Cond`不能被复制

不能被复制的原因，不是因为内部嵌套了`Locker`。因为 NewCond 时传入的 Mutex/RWMutex 指针，对于 Mutex 指针复制是没有问题的。<br />主要原因是`sync.Cond`内部是维护着一个 Goroutine 通知队列 `notifyList`。如果这个队列被复制的话，在并发场景下导致不同 Goroutine 之间操作的 notifyList.wait、notifyList.notify 并不是同一个，这会导致出现有些 Goroutine 会一直阻塞。

- 唤醒顺序

从等待队列中按照顺序唤醒，先进入等待队列，先被唤醒。

- 调用`Wait()`前要加锁

调用`Wait()`前，需要先获得条件变量的成员锁，原因是需要互斥地变更条件变量的等待队列。在`Wait()`返回前，会重新上锁。
<a name="mwzV0"></a>
# [golink](https://pkg.go.dev/cmd/compile)
使用 [go:linkname](https://github.com/golang/go/blob/master/src/cmd/compile/doc.go#L248) 让编译器编译的时候，把当前符号指向到目标符号。
```go
//go:linkname localname [importpath.name]
```
系统调用在 Go 里面相对来讲是比较重的，Runtime 会切换到 g0 栈中去执行这部分代码。通常可以用到的优化函数：

- `runtime.fastrand`：runtime 包生成的也是伪随机数，和 math 包不同的是，它的随机数生成使用的上下文是来自当前 Goroutine，所以不用加锁。
- `runtime.walltime1`：大部分场景下，只需要时间戳，Go<=1.16时`time.Now()`会有两次系统调用`runtime.walltime1`和`runtime.nanotime`。
- `runtime.nanotime`：如果只是统计某个函数的耗时。
- `runtime.memmove`：用于任意数据之间的内存拷贝，无视类型信息，直接操作内存。
   - 对于切片之间的数据拷贝，标准库提供的 copy 函数要更加方便一些。
   - memmove 更加适合字符串(string)和数组切片之间的数据拷贝场景。
- `runtime.growslice`：对于切片扩容，Go只提供了append函数来隐式的扩容，但内部是通过调用runtime 中的 growslice 来实现。
> 注意事项：linkname 为我们提供了一种方法，可以直接调用 Go 标准库里的未导出方法，可以读取未导出变量。使用时要注意 Go 版本更新后，是否有兼容问题，毕竟 Go 团队并没有保证这些未导出的方法变量后续不会变更。

<a name="ZRduq"></a>
# cgo
cgo 的支持让我们可以在 go 中调用 c/c++ 代码，但 cgo 的代码在运行期间不受 go 调度器的管理，为了防止cgo 调用引起调度阻塞，cgo 调用会切换到 g0 栈执行，并独占 M。由于 Runtime 设计时没有考虑 M 的回收，所以运行时间久了之后，会发现有 cgo 代码的程序，线程数都比较多。<br />用go的编译器转换包含 cgo 的代码：`go tool cgo main.go`，转换后cgo调用实际上是由`runtime.cgocall()`发起，而`runtime.cgocall()`调用过程主要分为以下几步：

1. `entersyscall()`: 保存上下文，标记当前 mincgo 独占 M，跳过垃圾回收。
2. `osPreemptExtEnter`：标记异步抢占，使异步抢占逻辑失效。
3. `asmcgocall`：真正的 cgo call 入口，切换到 g0 执行 c/c++ 代码。
4. 恢复之前的上下文，清理标记。

对于一些简单的 c 函数，可以直接用 asmcgocall 调用，避免来回切换：
```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
struct args{
    int p1,p2;
    int r;
};
int add(struct args* arg) {
    arg->r= arg->p1 + arg->p2;
    return 100;
}

```
```go
import "C"
import (
    "fmt"
    "unsafe"
)
//go:linkname asmcgocall runtime.asmcgocall
func asmcgocall(unsafe.Pointer, uintptr) int32

func main() {
    arg := C.struct_args{}
    arg.p1 = 100
    arg.p2 = 200
    //C.add(&arg)
    asmcgocall(C.add,uintptr(unsafe.Pointer(&arg)))
    fmt.Println(arg.r)
}
```
> 在包含 cgo 的代码编译时，将 ld 升级到 2.27 版本，编译后的体积可以减少约 50%。

<a name="j137D"></a>
# epoll
Runtime 对网络IO，以及定时器的管理，会放到自己维护的一个 epoll (`[runtime/netpool](https://github.com/golang/go/blob/master/src/runtime/netpoll_epoll.go)`)。在一些高并发的网络IO中，有以下几个问题：

1. 需要维护大量的协程去处理读写事件。
2. 对连接的状态无感知，必须要等待read或者write返回错误才能知道对端状态，其余时间只能等待。
3. 原生的 netpool 只维护一个 epoll，没有充分发挥多核优势。

基于此，有很多项目用`[x/unix](https://pkg.go.dev/golang.org/x/sys/unix)`扩展包实现了自己的基于epoll的网络库，比如[gnet](https://github.com/panjf2000/gnet)，字节跳动 [netpoll](https://github.com/cloudwego/netpoll)。
<a name="mfyw7"></a>
# SIMD
Go 链接器支持 simd 指令，但编译器不支持 simd 指令的生成。所以在 Go 中使用simd一般来说有三种方式：

1. 手写汇编。
2. llvm。
3. cgo（如果用cgo的方式来调用，会受限于cgo的性能，达不到加速的目的）。

目前比较流行的做法是 llvm：

1. 用 c 来写 simd 相关的函数，然后用 llvm 编译成 c 汇编。
2. 用工具把 c 汇编转换成 go 的汇编格式，保存为 .s 文件。
3. 在 go 中调用 .s 里的方法，最后用 go 编译器编译。

以下开源库用到了simd：[simdjson-go](https://github.com/minio/simdjson-go)、[sonic](https://github.com/bytedance/sonic)、[sha256-simd](https://github.com/minio/sha256-simd)<br />合理的使用 simd 可以充分发挥 cpu 特性，但是存在以下弊端：

1. 难以维护，要么需要懂汇编，要么需要引入第三方语言。
2. 跨平台支持不够，需要对不同平台汇编指令做适配。
3. 汇编代码很难调试，作为使用方来讲，完全黑盒。
<a name="iaGIL"></a>
# 参考
[Go 高性能编程技法](https://mp.weixin.qq.com/s?__biz=MjM5ODYwMjI2MA==&mid=2649769371&idx=1&sn=2aa88c3a960edeeeac98fbbe741e5207&chksm=beccd6e089bb5ff6e1f9c915f40af886cb00c42668395e1d13bb0fa53d254a712a1cc510eabd&mpshare=1&scene=1&srcid=0429WlhcAwB5IMyQeyynCLfJ&sharer_sharetime=1651220668140&sharer_shareid=4213fd857d5e1093a89959d8b61544cb&version=4.0.3.70108&platform=mac#rd)
